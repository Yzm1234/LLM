{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c32391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "from typing import List\n",
    " \n",
    "import torch\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.schema import BaseOutputParser\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    StoppingCriteria,\n",
    "    StoppingCriteriaList,\n",
    "    pipeline,\n",
    ")\n",
    " \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5320e5a",
   "metadata": {},
   "source": [
    "### base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da14122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37bb08f10a44733bf744b9868938155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the model\n",
    "BASE_MODEL_NAME = \"tiiuae/falcon-7b-instruct\"\n",
    " \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_NAME, device_map=\"auto\"\n",
    ")\n",
    "model = model.eval()\n",
    " \n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "# model genration config\n",
    "generation_config = model.generation_config\n",
    "generation_config.temperature = 0\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.max_new_tokens = 256\n",
    "generation_config.use_cache = False\n",
    "generation_config.repetition_penalty = 1.7\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    task=\"text-generation\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    " \n",
    "llm = HuggingFacePipeline(pipeline=generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4657962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current implementation of Falcon calls `torch.scaled_dot_product_attention` directly, this will be deprecated in the future in favor of the `BetterTransformer` API. Please install the latest optimum library with `pip install -U optimum` and call `model.to_bettertransformer()` to benefit from `torch.scaled_dot_product_attention` and future performance optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KBase is a free, open-source knowledge base software that allows users to create and maintain their own knowledge bases. It is designed to be easy to use and highly customizable, making it a great tool for businesses and individuals alike.\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"What is KBase?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74107918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To use KBase narrative, you need to first create a narrative object and then add it to a KViz scene. You can do this by using the `KViz::add_narrative()` function. Once added, you can customize the narrative by setting its properties, such as its text, color, and font. You can also add images and videos to the narrative by using the `KViz::add_image()` and `KViz::add_video()` functions. Finally, you can display the narrative in the scene by calling the `KViz::show()` function.\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"How to use KBase narrative?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf3763",
   "metadata": {},
   "source": [
    "### fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835bb326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7555a201581e4b5fb2635832f5a1fff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "TUNED_MODEL_NAME = \"fine_tuned_model_kbase_all_data\"\n",
    " \n",
    "tuned_model = AutoModelForCausalLM.from_pretrained(\n",
    "    TUNED_MODEL_NAME, device_map=\"auto\"\n",
    ")\n",
    "tuned_model = tuned_model.eval()\n",
    " \n",
    "tuned_model_tokenizer = AutoTokenizer.from_pretrained(TUNED_MODEL_NAME)\n",
    "\n",
    "tuned_model_generation_pipeline = pipeline(\n",
    "    model=tuned_model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    task=\"text-generation\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    " \n",
    "tuned_llm = HuggingFacePipeline(pipeline=tuned_model_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f096c3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KBase is a platform for analyzing and visualizing genomic data. It provides tools and resources to help researchers analyze their own or public genomes, including annotation, comparative analysis, functional enrichment analysis, and visualization of the results. KBase also offers an integrated development environment (IDE) called JupyterLab that allows users to perform these analyses in real-time using interactive code cells.\n"
     ]
    }
   ],
   "source": [
    "print(tuned_llm(\"What is KBase?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e008b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To use KBase narrative, you can follow these steps:\n",
      "\n",
      "1. Open the Narrative interface in your web browser and log in with your KBase account.\n",
      "2. Click on the 'New Story' button to create a new story.\n",
      "3. Give your story a title and select a template or start from scratch if desired.\n",
      "4. Add content to your story by dragging and dropping elements such as text, images, videos, and more into the canvas.\n",
      "5. Use Markdown syntax to format text and add hyperlinks.\n",
      "6. Save your changes and publish your story when ready.\n",
      "7. Share your story with others using various methods such as sharing links, embedding it on websites, or posting it on social media platforms.\n",
      "\n",
      "KBase provides detailed documentation and resources for users to learn how to effectively use the Narrative platform. You can access them through the help center and community forums.\n"
     ]
    }
   ],
   "source": [
    "print(tuned_llm(\"How to use KBase narrative?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc9276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
