{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e75c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "from typing import List\n",
    " \n",
    "import torch\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.schema import BaseOutputParser\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    StoppingCriteria,\n",
    "    StoppingCriteriaList,\n",
    "    pipeline,\n",
    ")\n",
    " \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911ccb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e61848d44b4b3b85b701971b6a556a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "MODEL_NAME = \"fine_tuned_model_kbase_all_data\"\n",
    " \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, device_map=\"auto\"\n",
    ")\n",
    "model = model.eval()\n",
    " \n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75a70516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model genration config\n",
    "generation_config = model.generation_config\n",
    "generation_config.temperature = 0\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.max_new_tokens = 256\n",
    "generation_config.use_cache = False\n",
    "generation_config.repetition_penalty = 1.7\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    task=\"text-generation\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    " \n",
    "llm = HuggingFacePipeline(pipeline=generation_pipeline)\n",
    "chain = ConversationChain(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c281fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prompt\n",
    "template = \"\"\"\n",
    "Current conversation:\n",
    "{history}\n",
    "Question: {input}\n",
    "Answer:\"\"\".strip()\n",
    " \n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f1ef578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add memory to the model\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"history\", k=6, return_only_outputs=True\n",
    ")\n",
    " \n",
    "chain = ConversationChain(llm=llm, memory=memory, prompt=prompt)#, verbose=True)\n",
    "def kbasebot(text_input):\n",
    "    res = chain.predict(input=text_input)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dea92b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To use KBase Narrative, you can follow these steps:\n",
      "\n",
      "1. Go to the KBase website and log in with your credentials.\n",
      "2. Click on the \"Narrative\" tab located at the top of the page.\n",
      "3. From there, you can create a new narrative or access an existing one.\n",
      "4. Once you have opened a narrative, you can start adding content by clicking on the \"+ Add Content\" button. This will open up a menu where you can choose from various types of objects to add to your narrative.\n",
      "5. You can also drag and drop files into your narrative directly from your computer.\n",
      "6. After adding content, you can arrange it within your narrative using layout options such as tabs, sections, and columns.\n",
      "7. When finished editing, click on the \"Save Changes\" button to save your work.\n",
      "8. Your changes will be saved automatically, but if any issues arise, you can always revert back to previous versions of your narrative using version control tools.\n",
      "\n",
      "In summary, KBase Narrative is a versatile tool that enables scientists to organize and share their research data effectively. By following these simple steps, users can seamlessly build and maintain their narratives without requiring extensive technical expertise.\n"
     ]
    }
   ],
   "source": [
    "print(kbasebot(\"how to use KBase narrative?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5471ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! The third step involves adding the required number of zeroes to each column that contains non-zero values. For example, if there are 5 rows and the first row has a value in the second column, the code will add five zeros to the left of that value in order to meet the requirement of having exactly one space per data element. This ensures consistent spacing between columns even when some have different lengths.\n"
     ]
    }
   ],
   "source": [
    "print(kbasebot(\"can you explain more for the third step?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "232e84d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the context of using KBase narrative, the third step involves adding leading zeros to columns that contain non-zero values. This is done to ensure consistency in spacing across columns, regardless of the length of individual entries. By doing this, it helps maintain an organized appearance of the dataset while also making it easier to analyze and interpret.\n"
     ]
    }
   ],
   "source": [
    "print(kbasebot(\"can you explain more for the third step in how to use KBase narrative?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379dbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
